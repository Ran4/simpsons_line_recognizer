\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[swedish]{babel}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{float}
\usepackage{endnotes}
\usepackage{alltt}
\usepackage{listings}
\usepackage{hyperref}
\author{Anton Kindestam antonki@kth.se\\Rasmus Ansin ransin@kth.se}
\title{Replikidentifiering av karaktärer från tv-serien The Simpsons med N-Grams}

\begin{document}
\maketitle
% Bedömningsgrunder:
%    Avgränsning: att visa prov på förmåga att sätta ramarna för arbetet, bl.a. genom kontakter med handledare.
%    Språkteknologisk höjd: att utgå ifrån andras arbete, där det är tillämpbart. Att inte upprepa kända misstag.
%    Metodval: att kunna strukturera uppgiften, välja lämplig metod för varje delmoment.
%    Nyhetsvärde: att visa förmåga till egen lösning samt att själva lösningen av uppgiften ger ett litet litet nyhetsvärde.
%    För labbuppgiften: att leverera en fungerande prototyp, genomföra mindre test/utvärdering.
%    För utvärderingsuppgiften: att kunna hantera olika utvärderingsbegrepp, välja lämpliga mätmetoder, lämpliga utvärderingsdata, ge resonemang om utvärderingens validitet.
%    Teoretisk förståelse: att kunna hantera språkteknologiska begrepp och teori i viss utsträckning.
%    Visa förståelse för kursens huvudpoänger: metoder som verkligen fungerar, fokus på program med hög användbarhet.
%    Rapportens innehåll: finns alla väsentliga delar med: bakgrund, utgångspunkt/tanke, metod och resultat?
%    Rapportens språk: språkligt flyt och grad av korrekturläsning.
%    Explicita referenser: när andras verktyg, lexikon, teorier osv. används skall detta explicit redovisas.

\section{Bakgrund}
Vi har valt att analysera repliker av The Simpsons-avsnitt för att
skapa en klassificerare som kan klassificera vilken yttring som
tillhör vilken Simpsons-rollfigur. Vi gör detta genom att skapa en
n-gram-databas över yttringar kopplade till rollfigurer. För en given
mening generar vi dess n-gram, och sen väljer vi den rollfigur för
vilken denna n-gram-sekvens är sannolikast.


\section{Utgångspunkt}

Vi har utgått från en samling med manuskript från den amerikanska
tv-serien The Simpsons som vi fann på webbsidan
\url{http://www.simpsoncrazy.com/scripts}

\section{Metod}

\subsection{Inläsning av data}
Manuskripten från \nolinkurl{simpsonscrazy.com} har följande form:
\begin{verbatim}
ACT ONE

"The Simpsons Christmas Special" appears on screen. The episode begins with Homer,
Marge and Maggie arriving at Springfield Elementary School.
They are late for the schools' Christmas show.

MARGE
(Angry) Oh, careful, Homer!

HOMER
There's no time to be careful, we're late.

They enter the hall. A class is singing "Oh, Little Town of Bethlehem".

MARGE
Sorry, excuse me, pardon me, sorry.
\end{verbatim}

Vi sparar dessa i ett råtextformat och gör en första filtrering av
dessa rader genom att ta bort ACT-taggarna och radera ord och meningar
som skrivs inom en parentes.

Den något modifierade filen läses sedan in rad för rad till ett
Pythonscript. Vi plockar ut de rader som följs av en rad bestående av
enbart versaler (ett namn).

Varje rad vi läser in filtreras ytterligare genom att alla tecken som
inte är av typen \verb=[a-zA-Z']= tas bort. Resultatet är nu av det
här slaget:

\begin{verbatim}
$ python read_lines_from_file.py 01_01_raw.txt
repliker = {
    "MARGE": ["oh careful homer"], ["sorry excuse me pardon me sorry"],
    "HOMER": ["there's no time to be careful we're late"]
}
\end{verbatim}

\subsection{Generering av N-Gram}
Från replikerna genereras därefter n-gram för olika n-värden, vilka
bildar vårt korpus.

\begin{verbatim}
grams = {
  2:{
    "MARGE": ["oh careful", "careful homer", "sorry excuse",
              "excuse me", "me pardon", "pardon me", "me sorry"],
    "HOMER": ["there's no", "no time", "time to", "to be",
                  "be careful", "careful we're", "we're late"]
] }
  3:{
    "MARGE": ["oh careful homer", "sorry excuse me", "excuse me pardon",
              "me pardon me", "pardon me sorry"],
    "HOMER": ["there's no time", "no time to", "time to be",
              "to be careful", "be careful we're", "careful we're late"]
  }
}
\end{verbatim}

\subsection{Stopplistor}
Vi är intresserade av n-gram som är särskiljande. För att vanligt förekommande
n-gram inte ska räknas plockar vi bort dem med hjälp av en stopplista. Vi
skapade en första stopplista genom att lista de vanligast förekommande n-grammen
sett över alla karaktärers n-gram. Till denna stopplista lades sedan de 100
vanligaste engelska n-grammen till, från Corpus of Contemporary American English
(COCA)\footnote{\url{http://www.ngrams.info/download_coca.asp}}. Genom att
exkludera dess n-gram ur n-gram-databasen och ur meningar innan klassificering
hoppas vi förbättra precisionen hos klassificeraren.


\subsection{Precision, Återkallning, $F_1$-mått}
För att kunna utvärdera hur väl vår klassificerare fungerar så använder vi
måtten precision, återkallning och beräknar ett $F_1$-mått.

Precision är den andel av de fall som klassificerades positivt som var rätt.
Återkallning är den andel av de positiva exemplen i våra data som fångades av
vår klassificerare. $F_1$-mått är det harmoniska medelvärdet av precision och
återkallning, och används eftersom det är svårt att jämföra två olika
utvärderingsmått.

\begin{align*}
\text{precision}&=\dfrac{\text{sanna positiva}}{\text{sanna positiva} + \text{falska positiva}}\\
\text{återkallning}&=\dfrac{\text{sanna positiva}}{\text{sanna positiva} + \text{falska positiva}}\\
F_1 &= 2 \cdot \dfrac{\text{precision} \cdot \text{återkallning}}{\text{precision} + \text{återkallning}}
\end{align*}




\subsection{Korsvalidering}
Korsvalidering går ut på att man delar upp sitt dataset i ett testset och
träningsset. Man brukar dela upp det så att träningssetet innehåller all data
förutom den som tillhör testsetet. Man roterar sedan det som ingår i testsetet
och träningssetet så att all data i det totala datasetet har klassificerats av
klassificeraren, utan att det dataset man klassificerar ingår i träningsdatan
när man klassificerar.

I vårt projekt har vi gjort korsvalidering på avsnittsnivå. Vi tar bort ett
avsnitt från alla avsnitt vi har och tränar klassificeraren på återstående data.
Sen klassificerar vi det borttagna avsnittet och mäter hur väl klassificeraren
kan hitta vem som sa vad i det borttagna avsnittet, jämfört med namnen som står
i manuset.

\subsection{Poängfunktioner}
För att koppla en specifik mening till en viss karaktär så har en funktion som
beräknar ett poängvärde för varje rad och karaktär skapats. Den karaktär som ger
högst poäng för en viss rad kopplas ihop med den raden.

\begin{lstlisting}[mathescape, columns=fullflexible, basicstyle=\fontfamily{lmvtt}\selectfont]
function calculate_points_for_ngrams(all_ngrams, ngram, name):
    return all_ngrams.count(ngram)

function calculate_score_for_line(all_ngrams, line, name):
    points $\leftarrow$ 0
    for each ngram n in line:
        points $\leftarrow$ points $+$ calculate_points_for_ngram(all_ngrams, n, name)
    return points
\end{lstlisting}

Vi använder även en bättre variant, där vi tar hänsyn till hur "unikt" varje
n-gram är hos en karaktär.

Om ett visst n-gram förekommer $X$ gånger hos karaktär A, $Y$ gånger hos karaktär B
och $Z$ gånger hos karaktär C får ett n-gram poängen $X/(Y+Z)$ för karaktär A,
$Y/(X+Z)$ för karaktär B och $Z/(X+Y)$ för karaktär C.

\begin{lstlisting}[mathescape, columns=fullflexible, basicstyle=\fontfamily{lmvtt}\selectfont]
function calculate_score_for_line_improved(all_ngrams, line, name):
    ngrams $\leftarrow$ all_ngrams without those associated with character name 
    points $\leftarrow  \dfrac{\text{calculate\_score\_for\_line(all\_ngrams, line, name)}}{\text{calculate\_points\_for\_ngram(ngrams, n, name)}}$
    return points
\end{lstlisting}

\section{Resultat av korsvalidering}
\begin{verbatim}
--------------------------------------------------
without score function
--------------------------------------------------
Correct guesses: 896 (33.9%), incorrect guesses: 1748
Diagonal Sum: 896 (0.338880), Non-Diagonal Sum: 1748 (0.661120)
Rows: Correct name, Columns: Guessed name
      HOMER  LISA BURNS  BART MARGE 
HOMER   343   172   129   220   246 
 LISA    46   100    50    74   102 
BURNS    27    23    66    17    54 
 BART    77   118    42   142   112 
MARGE    42    79    60    58   245 

        Precision  Recall     F1Score    
HOMER:  0.641      0.309      0.417      
LISA:   0.203      0.269      0.231      
BURNS:  0.190      0.353      0.247      
BART:   0.278      0.289      0.283      
MARGE:  0.323      0.506      0.394      
avg:    0.327      0.345      0.314      

Using stoplist with length: 187
Correct guesses: 882 (33.4%), incorrect guesses: 1762
Diagonal Sum: 882 (0.333585), Non-Diagonal Sum: 1762 (0.666415)
Rows: Correct name, Columns: Guessed name
      HOMER  LISA BURNS  BART MARGE 
HOMER   315   193   119   234   249 
 LISA    53   106    41    75    97 
BURNS    21    27    64    19    56 
 BART    71   129    38   157    96 
MARGE    46    88    45    65   240 

        Precision  Recall     F1Score    
HOMER:  0.623      0.284      0.390      
LISA:   0.195      0.285      0.232      
BURNS:  0.208      0.342      0.259      
BART:   0.285      0.320      0.302      
MARGE:  0.325      0.496      0.393      
avg:    0.327      0.345      0.315      

--------------------------------------------------
with score function
--------------------------------------------------
Correct guesses: 906 (34.3%), incorrect guesses: 1738
Diagonal Sum: 906 (0.342663), Non-Diagonal Sum: 1738 (0.657337)
Rows: Correct name, Columns: Guessed name
      HOMER  LISA BURNS  BART MARGE 
HOMER   393   105   103   181   328 
 LISA    76    55    29    76   136 
BURNS    36    17    40    18    76 
 BART   113    53    29   141   155 
MARGE    76    45    42    44   277 

        Precision  Recall     F1Score    
HOMER:  0.566      0.354      0.436      
LISA:   0.200      0.148      0.170      
BURNS:  0.165      0.214      0.186      
BART:   0.307      0.287      0.297      
MARGE:  0.285      0.572      0.380      
avg:    0.305      0.315      0.294      

Using stoplist with length: 187
Correct guesses: 911 (34.5%), incorrect guesses: 1733
Diagonal Sum: 911 (0.344554), Non-Diagonal Sum: 1733 (0.655446)
Rows: Correct name, Columns: Guessed name
      HOMER  LISA BURNS  BART MARGE 
HOMER   398   109   104   189   310 
 LISA    79    57    30    81   125 
BURNS    40    21    42    20    64 
 BART   120    61    30   149   131 
MARGE    83    46    44    46   265 

        Precision  Recall     F1Score    
HOMER:  0.553      0.359      0.435      
LISA:   0.194      0.153      0.171      
BURNS:  0.168      0.225      0.192      
BART:   0.307      0.303      0.305      
MARGE:  0.296      0.548      0.384      
avg:    0.304      0.318      0.297      
\end{verbatim}


\section{Utvärdering}
Vårt korpus är för litet för uppgiften. Det visar sig att det var svårare än vi
räknat med att få tag i avskrift av Simpsons-avsnitt på nätet. Det visar sig
även att Homer har flest repliker (över hälften) så vårt korpus är
snedbalanserat och tenderar att föredra
Homer\footnote{\url{http://www.vikparuchuri.com/blog/figuring-out-which-simpsons-character-is-speaking/}}.
Antalet korrekt klassificerade repliker är alltså ett dåligt mått, då en
gissning på Homer för alla repliker kommer ge över 50\% korrekta svar. Vi kan
dock trösta oss med att vår klassificerare i alla fall ger bättre resultat än
att gissa slumpmässigt.
% TODO: vi behöver ev. ta med några slumpade resultat i rapporten för att motivera detta

%Saker att diskutera:
%allt på http://www.csc.kth.se/~jboye/teaching/sprakt/2015_Utvardering.pdf
%Intrinsic/Extrinsic evaluation
%Black Box/Glass Box
%Overfitting

%Accuracy: Consider precision (TP/(TP+FP)) and recall (TP/(FP+FN))
%F-Measure: F_1 = 2 * precision*recall / (precision + recall)

\end{document}































